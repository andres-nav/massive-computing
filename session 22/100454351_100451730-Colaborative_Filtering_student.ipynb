{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9914840f-bf36-4fe7-b4bb-323e0a80ad87",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "version 2\n",
    "# Alejo Gonzalez Garcia (100454351)\n",
    "# AndrÃ©s Navarro Pedregal (100451730)\n",
    "\n",
    "# ![Spark Logo](http://spark-mooc.github.io/web-assets/images/ta_Spark-logo-small.png) + ![Python Logo](http://spark-mooc.github.io/web-assets/images/python-logo-master-v3-TM-flattened_small.png)\n",
    "# **Introduction to Machine Learning with Apache Spark**\n",
    "## **Predicting Movie Ratings**\n",
    "#### One of the most common uses of big data is to predict what users want.  This allows Google to show you relevant ads, Amazon to recommend relevant products, and Netflix to recommend movies that you might like.  This lab will demonstrate how we can use Apache Spark to recommend movies to a user.  We will start with some basic techniques, and then use the [Spark MLlib][mllib] library's Alternating Least Squares method to make more sophisticated predictions.\n",
    "#### For this lab, we will use a subset dataset of 500,000 ratings we have included for you into your VM (and on Databricks) from the [movielens 10M stable benchmark rating dataset](http://grouplens.org/datasets/movielens/). However, the same code you write will work for the full dataset, or their latest dataset of 21 million ratings.\n",
    "#### In this lab:\n",
    "#### *Part 0*: Preliminaries\n",
    "#### *Part 1*: Basic Recommendations\n",
    "#### *Part 2*: Collaborative Filtering\n",
    "#### *Part 3*: Predictions for Yourself\n",
    "#### As mentioned during the first Learning Spark lab, think carefully before calling `collect()` on any datasets.  When you are using a small dataset, calling `collect()` and then using Python to get a sense for the data locally (in the driver program) will work fine, but this will not work when you are using a large dataset that doesn't fit in memory on one machine.  Solutions that call `collect()` and do local analysis that could have been done with Spark will likely fail in the autograder and not receive full credit.\n",
    "[mllib]: https://spark.apache.org/mllib/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cfed36f2-18e1-40c6-8e3d-79b68dc148ad",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Code\n",
    "#### This assignment can be completed using basic Python and pySpark Transformations and Actions.  Libraries other than math are not necessary. With the exception of the ML functions that we introduce in this assignment, you should be able to complete all parts of this homework using only the Spark functions you have used in prior lab exercises (although you are welcome to use more features of Spark if you like!).\n",
    "### You will need to import the h5py and implicit Python packages to get the MoviLENS databases.\n",
    "### Import those packages go to Workspace -> Users -> right button and select Import. In the Modal Window select \"import a library\"  and select Package from PyPy.\n",
    "#### Fill the Package name field with h5py and repeat with the implicit library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4e4db859-6f0e-43c3-adfa-47064670c788",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from test_helper import Test\n",
    "from implicit.datasets.movielens import get_movielens\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5fa91a1f-9f1d-45e2-973b-1e3fd21116c3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b7e34fd4-aa66-4b97-ad2e-723b945e6675",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### **Part 0: Preliminaries**\n",
    "#### We read with implicit the dataset to analyze.\n",
    "#### MovieLens have 4 different datasets, with different amount of movies and ratings.\n",
    "#### We have: '100k', '1m', '10m' and '20m', and define it in the variant variable\n",
    "#### \n",
    "* #### For each row in the ratings dataset, we create a tuple of (UserID, MovieID, Rating). \n",
    "* #### For each line in the movies dataset, we create a tuple of (MovieID, Title)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6116d285-5f7f-4d9b-bc85-0d90594d0d08",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "variant='1m'\n",
    "titles, ratings = get_movielens(variant)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f0feb4cf-0e69-4406-8b1e-bf7c1cb59ef6",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Check the data in titles variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b6b851b5-7f79-452e-a21e-fff7ed0385e3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['' 'Toy Story (1995)' 'Jumanji (1995)' ... 'Tigerland (2000)'\n",
      " 'Two Family House (2000)' 'Contender, The (2000)']\n"
     ]
    }
   ],
   "source": [
    "print(titles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ffde7cfb-f763-42fc-91ef-0d01b964a99b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "It is a very simple list of titles. We will assume the movieID is her possition in the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "87412b9c-403c-472e-b18d-32fb71169674",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "moviesRDD=sc.parallelize(zip(range(len(titles)),titles)).map(lambda p: Row(movieId=int(p[0]),Title=str(p[1])))\n",
    "moviesDF=spark.createDataFrame(moviesRDD)\n",
    "moviesCount=moviesDF.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e81b47c3-45d3-479e-8ac9-2d21948edc3f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+\n",
      "|movieId|               Title|\n",
      "+-------+--------------------+\n",
      "|      0|                    |\n",
      "|      1|    Toy Story (1995)|\n",
      "|      2|      Jumanji (1995)|\n",
      "|      3|Grumpier Old Men ...|\n",
      "|      4|Waiting to Exhale...|\n",
      "|      5|Father of the Bri...|\n",
      "|      6|         Heat (1995)|\n",
      "|      7|      Sabrina (1995)|\n",
      "|      8| Tom and Huck (1995)|\n",
      "|      9| Sudden Death (1995)|\n",
      "|     10|    GoldenEye (1995)|\n",
      "|     11|American Presiden...|\n",
      "|     12|Dracula: Dead and...|\n",
      "|     13|        Balto (1995)|\n",
      "|     14|        Nixon (1995)|\n",
      "|     15|Cutthroat Island ...|\n",
      "|     16|       Casino (1995)|\n",
      "|     17|Sense and Sensibi...|\n",
      "|     18|   Four Rooms (1995)|\n",
      "|     19|Ace Ventura: When...|\n",
      "+-------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "moviesDF.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c413e3d3-1d7c-4038-a281-6eba83707ebb",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Now, we will check the ratings information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0357af47-db94-45fc-baec-26646e1d8621",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[61]: scipy.sparse.csr.csr_matrix"
     ]
    }
   ],
   "source": [
    "type(ratings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f319eb0c-8568-49c9-8172-9933d29d2b1e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "It is a scipy.sparse.csr.csr_matrix [https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.csr_matrix.html].\n",
    "\n",
    "In this case the matrix represents the evaluation of each one of the movies (rows) by the each user (columns). Thats why this matrix is full of zeros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5aa401dc-d749-43ff-b108-30d35953f94a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[62]: array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0.],\n",
      "       [0., 5., 0., 0., 0., 0., 4., 0., 4., 5., 5., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 4., 5.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 5., 0., 0., 3., 0., 0.,\n",
      "        0., 0., 2., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 3., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0.]], dtype=float32)"
     ]
    }
   ],
   "source": [
    "(ratings.toarray())[0:5,0:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "106ac972-fb17-44ca-8705-3cf7ce864b7d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "To get tle list of tuples with pair (movie, user) and evaluation, we can use the method todok() [https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.csr_matrix.todok.html#scipy.sparse.csr_matrix.todok]. This will be useful to convert to a distributed dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6a22b88a-955b-488b-ae83-f97668dc15ec",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[63]: 1000209"
     ]
    }
   ],
   "source": [
    "len(ratings.todok(True).items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "efacc8df-0e7d-4b73-a27c-aa8ea2ee969e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[64]: [((1, 1), 5.0),\n",
      " ((48, 1), 5.0),\n",
      " ((150, 1), 5.0),\n",
      " ((260, 1), 4.0),\n",
      " ((527, 1), 5.0),\n",
      " ((531, 1), 4.0),\n",
      " ((588, 1), 4.0),\n",
      " ((594, 1), 4.0),\n",
      " ((595, 1), 5.0),\n",
      " ((608, 1), 4.0)]"
     ]
    }
   ],
   "source": [
    "list(ratings.todok(True).items())[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "305e6af5-92bb-4115-9fd0-5772bfa6a86b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def get_ratings_tuple(entry):\n",
    "    #Program a function who receives a tuple ((movieId, userId), rating) and returns a tuple (userId,MovieId,rating)\n",
    "\n",
    "    # Unpack the nested tuple\n",
    "    (movieId, userId), rating = entry\n",
    "    \n",
    "    # Return the transformed tuple\n",
    "    return userId, movieId, rating\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a90836c2-824a-4044-8f80-27a2017ad922",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "rawRatingsRDD=sc.parallelize(list(ratings.todok(True).items()))\n",
    "ratingsRDD = ( rawRatingsRDD\n",
    "                 .map(get_ratings_tuple)\n",
    "                 .map(lambda p: Row(userId=int(p[0]), movieId=int(p[1]), rating=float(p[2])))\n",
    "            )\n",
    "ratingsDF = spark.createDataFrame(ratingsRDD)\n",
    "ratingsCount = ratingsDF.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "12344fe5-a2be-48ca-87ea-acbc6f6dee95",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1000209 ratings and 3953 movies in the datasets\n",
      "Ratings: [Row(userId=1, movieId=1, rating=5.0), Row(userId=1, movieId=48, rating=5.0), Row(userId=1, movieId=150, rating=5.0)]\n",
      "Movies: [Row(movieId=0, Title=''), Row(movieId=1, Title='Toy Story (1995)'), Row(movieId=2, Title='Jumanji (1995)')]\n"
     ]
    }
   ],
   "source": [
    "print ('There are {0} ratings and {1} movies in the datasets'.format(ratingsCount, moviesCount))\n",
    "print ('Ratings: {0}'.format(ratingsDF.take(3)))\n",
    "print ('Movies: {0}'.format(moviesDF.take(3)))\n",
    "if variant=='20m':\n",
    "  assert ratingsCount == 20000263\n",
    "  assert moviesCount == 131263\n",
    "  assert moviesDF.filter(\"Title == \\\"b'Toy Story (1995)'\\\"\").count() == 1\n",
    "  assert (ratingsRDD.takeOrdered(1, key=lambda data: data[1]))\n",
    "if variant=='10m':\n",
    "  assert ratingsCount == 10000054\n",
    "  assert moviesCount == 65134\n",
    "  assert moviesDF.filter(\"Title == \\\"b'Toy Story (1995)'\\\"\").count() == 1\n",
    "  assert (ratingsRDD.takeOrdered(1, key=lambda data: data[1]))\n",
    "if variant=='1m':\n",
    "  assert ratingsCount == 1000209\n",
    "  assert moviesCount == 3953\n",
    "  #assert moviesDF.filter(\"Title == \\\"b'Toy Story (1995)'\\\"\").count() == 1 # We can have both, I have fixed the output error!\n",
    "  assert moviesDF.filter(\"Title == \\\"b'Toy Story (1995)'\\\" OR Title == 'Toy Story (1995)'\").count() == 1\n",
    "\n",
    "  assert (ratingsRDD.takeOrdered(1, key=lambda data: data[1]))\n",
    "if variant=='100k':\n",
    "  assert ratingsCount == 100000\n",
    "  assert moviesCount == 1683\n",
    "  assert moviesDF.filter(\"Title == \\\"b'Toy Story (1995)'\\\"\").count() == 1\n",
    "  assert (ratingsRDD.takeOrdered(1, key=lambda data: data[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6c679f5c-e7e5-4092-99e8-7ac3540b6561",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### In this lab we will be examining subsets of the tuples we create (e.g., the top rated movies by users). Whenever we examine only a subset of a large dataset, there is the potential that the result will depend on the order we perform operations, such as joins, or how the data is partitioned across the workers. What we want to guarantee is that we always see the same results for a subset, independent of how we manipulate or store the data.\n",
    "#### We can do that by sorting before we examine a subset. You might think that the most obvious choice when dealing with an RDD of tuples would be to use the [`sortByKey()` method][sortbykey]. However this choice is problematic, as we can still end up with different results if the key is not unique.\n",
    "#### Note: It is important to use the [`unicode` type](https://docs.python.org/2/howto/unicode.html#the-unicode-type) instead of the `string` type as the titles are in unicode characters.\n",
    "#### Consider the following example, and note that while the sets are equal, the printed lists are usually in different order by value, *although they may randomly match up from time to time.*\n",
    "#### You can try running this multiple times.  If the last assertion fails, don't worry about it: that was just the luck of the draw.  And note that in some environments the results may be more deterministic.\n",
    "[sortbykey]: https://spark.apache.org/docs/latest/api/python/pyspark.html#pyspark.RDD.sortByKey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "99015630-49c4-4e69-acd9-a80281a92e74",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Row(key=1, value='alpha'), Row(key=1, value='epsilon'), Row(key=1, value='delta'), Row(key=2, value='alpha'), Row(key=2, value='beta'), Row(key=3, value='alpha')]\n",
      "[Row(key=1, value='delta'), Row(key=1, value='epsilon'), Row(key=1, value='alpha'), Row(key=2, value='alpha'), Row(key=2, value='beta'), Row(key=3, value='alpha')]\n"
     ]
    }
   ],
   "source": [
    "tmp1 = [(1, u'alpha'), (2, u'alpha'), (2, u'beta'), (3, u'alpha'), (1, u'epsilon'), (1, u'delta')]\n",
    "tmp2 = [(1, u'delta'), (2, u'alpha'), (2, u'beta'), (3, u'alpha'), (1, u'epsilon'), (1, u'alpha')]\n",
    "schema=[\"key\",\"value\"]\n",
    "oneDF = spark.createDataFrame(data=tmp1,schema=schema)\n",
    "twoDF = spark.createDataFrame(data=tmp2,schema=schema)\n",
    "oneSorted = oneDF.sort(\"key\").collect()\n",
    "twoSorted = twoDF.sort(\"key\").collect()\n",
    "print (oneSorted)\n",
    "print (twoSorted)\n",
    "assert set(oneSorted) == set(twoSorted)     # Note that both lists have the same elements\n",
    "assert twoSorted[0][\"key\"] < twoSorted.pop()[\"key\"] # Check that it is sorted by the keys\n",
    "assert oneSorted != twoSorted   # Note that the subset consisting of the first two elements does not match"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "11b4941f-1bae-4fff-83b4-31d95bbdf689",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Even though the two lists contain identical tuples, the difference in ordering *sometimes* yields a different ordering for the sorted DF (try running the cell repeatedly and see if the results change or the assertion fails). If we only examined the first two elements of the DF (e.g., using `take(2)`), then we would observe different answers - **that is a really bad outcome as we want identical input data to always yield identical output**. A better technique is to sort the DF by *both the key and value*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b1601ff2-a919-4643-ad33-de9780684025",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Row(key=1, value='alpha'), Row(key=1, value='delta'), Row(key=1, value='epsilon'), Row(key=2, value='alpha'), Row(key=2, value='beta'), Row(key=3, value='alpha')]\n",
      "[Row(key=1, value='alpha'), Row(key=1, value='delta'), Row(key=1, value='epsilon'), Row(key=2, value='alpha'), Row(key=2, value='beta'), Row(key=3, value='alpha')]\n"
     ]
    }
   ],
   "source": [
    "print (oneDF.sort(\"key\", \"value\").collect())\n",
    "print (twoDF.sort(\"key\",\"value\").collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "687aef33-6091-4b02-974c-30b317fe06c5",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### If we just want to look at the first few elements of the DF in sorted order, we can use the sort method with multiple columns defining the priority to sort: https://spark.apache.org/docs/3.1.2/api/python/reference/api/pyspark.sql.DataFrame.sort.html#pyspark.sql.DataFrame.sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "70e7b175-c029-4b78-a6bc-f0cc30c4778f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one is [Row(key=1, value='alpha'), Row(key=1, value='delta'), Row(key=1, value='epsilon'), Row(key=2, value='alpha'), Row(key=2, value='beta'), Row(key=3, value='alpha')]\n",
      "two is [Row(key=1, value='alpha'), Row(key=1, value='delta'), Row(key=1, value='epsilon'), Row(key=2, value='alpha'), Row(key=2, value='beta'), Row(key=3, value='alpha')]\n"
     ]
    }
   ],
   "source": [
    "oneSorted1 = oneDF.sort(\"key\", \"value\").take(oneDF.count())\n",
    "twoSorted1 = twoDF.sort(\"key\", \"value\").take(oneDF.count())\n",
    "print ('one is {0}'.format(oneSorted1))\n",
    "print ('two is {0}'.format(twoSorted1))\n",
    "assert oneSorted1 == twoSorted1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0323fd8b-3da0-41f9-838d-1ad3957f0d99",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### **Part 1: Basic Recommendations**\n",
    "#### One way to recommend movies is to always recommend the movies with the highest average rating. In this part, we will use Spark to find the name, number of ratings, and the average rating of the 20 movies with the highest average rating and more than 500 reviews. We want to filter our movies with high ratings but fewer than or equal to 500 reviews because movies with few reviews may not have broad appeal to everyone."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7a1c4125-a052-4e8a-9023-f159909c0af9",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### **(1a) Movies with Highest Average Ratings**\n",
    "#### Now that we have a way to calculate the average ratings, we will use the `getCountsAndAverages()` helper function with Spark to determine movies with highest average ratings.\n",
    "#### The steps you should perform are:\n",
    "* #### Recall that the `ratingsDF` contains tuples of the form (UserID, MovieID, Rating). From `ratingsDF` create an DataFrame with tuples of the form (MovieID, number of ratings, average of ratings). Use the methods \n",
    "* #### groubBy() https://spark.apache.org/docs/3.1.2/api/python/reference/api/pyspark.sql.DataFrame.groupBy.html#pyspark.sql.DataFrame.groupBy\n",
    "### And agg() method https://spark.apache.org/docs/3.1.2/api/python/reference/api/pyspark.sql.DataFrame.agg.html#pyspark.sql.DataFrame.agg, to calculate the number of ratings and average value of ratings per movie. \n",
    "* #### We want to see movie names, instead of movie IDs. To `moviesRDD`, apply DataFrame transformations that use `movieIDsWithAvgRatingsDF` to get the movie names for `movieIDsWithAvgRatingsDF`, yielding tuples of the form (average rating, movie name, number of ratings). This set of transformations will yield an DF of the form: `[(1.0, u'Autopsy (Macchie Solari) (1975)', 1), (1.0, u'Better Living (1998)', 1), (1.0, u'Big Squeeze, The (1996)', 3)]`. You can use the Spark Dataframe transformation *join* https://spark.apache.org/docs/3.1.2/api/python/reference/api/pyspark.sql.DataFrame.join.html#pyspark.sql.DataFrame.join : `[(3.6818181818181817, u'Happiest Millionaire, The (1967)', 22), (3.0468227424749164, u'Grumpier Old Men (1995)', 299), (2.882978723404255, u'Hocus Pocus (1993)', 94)]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fb793437-b5c0-4ee0-932a-155eb1ec628a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "movieIDsWithAvgRatingsRDD: [Row(movieId=29, num_rating=403, avg_rating=4.062034739454094), Row(movieId=1806, num_rating=168, avg_rating=2.892857142857143), Row(movieId=474, num_rating=972, avg_rating=3.825102880658436)]\n",
      "\n",
      "movieNameWithAvgRatingsDF: [Row(avg_rating=5.0, Title='Schlafes Bruder (Brother of Sleep) (1995)', num_rating=1), Row(avg_rating=5.0, Title='Bittersweet Motel (2000)', num_rating=1), Row(avg_rating=5.0, Title='Follow the Bitch (1998)', num_rating=1)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TODO: Replace <FILL IN> with appropriate code\n",
    "\n",
    "# From ratingsDF with tuples of (UserID, MovieID, Rating) create an DF with MovieId, number of ratings and average of that ratings.\n",
    "# Set name as movieId, num_ratings and avg_ratings\n",
    "# the (MovieID, iterable of Ratings for that MovieID)\n",
    "\n",
    "movieIDsWithRatingsDF = ratingsDF.groupBy('movieId').agg(\n",
    "    count('rating').alias('num_rating'),\n",
    "    avg('rating').alias('avg_rating')\n",
    ")\n",
    "print ('movieIDsWithAvgRatingsRDD: {0}\\n'.format(movieIDsWithRatingsDF.take(3)))\n",
    "\n",
    "# To `movieIDsWithAvgRatingsRDD`, apply RDD transformations that use `moviesRDD` to get the movie\n",
    "# names for `movieIDsWithAvgRatingsRDD`, yielding tuples of the form\n",
    "# (average rating, movie name, number of ratings)\n",
    "movieNameWithAvgRatingsDF = (moviesDF\n",
    "                              .join(movieIDsWithRatingsDF, 'movieId')\n",
    "                              .select('avg_rating', 'Title', 'num_rating')\n",
    "                              .orderBy('avg_rating', ascending=False))\n",
    "\n",
    "print('movieNameWithAvgRatingsDF: {0}\\n'.format(movieNameWithAvgRatingsDF.take(3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cbd912b5-6859-4ae6-96c7-e9de236fc333",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+\n",
      "|userId|movieId|rating|\n",
      "+------+-------+------+\n",
      "|     1|      1|   5.0|\n",
      "|     1|     48|   5.0|\n",
      "|     1|    150|   5.0|\n",
      "|     1|    260|   4.0|\n",
      "|     1|    527|   5.0|\n",
      "|     1|    531|   4.0|\n",
      "|     1|    588|   4.0|\n",
      "|     1|    594|   4.0|\n",
      "|     1|    595|   5.0|\n",
      "|     1|    608|   4.0|\n",
      "|     1|    661|   3.0|\n",
      "|     1|    720|   3.0|\n",
      "|     1|    745|   3.0|\n",
      "|     1|    783|   4.0|\n",
      "|     1|    914|   3.0|\n",
      "|     1|    919|   4.0|\n",
      "|     1|    938|   4.0|\n",
      "|     1|   1022|   5.0|\n",
      "|     1|   1028|   5.0|\n",
      "|     1|   1029|   5.0|\n",
      "+------+-------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ratingsDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "99bebab9-b2be-4de0-9179-f7b99b1dd988",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+------------------+\n",
      "|movieId|num_rating|        avg_rating|\n",
      "+-------+----------+------------------+\n",
      "|     29|       403| 4.062034739454094|\n",
      "|   1806|       168| 2.892857142857143|\n",
      "|    474|       972| 3.825102880658436|\n",
      "|   2040|       128|         2.9453125|\n",
      "|   2453|       176|              3.25|\n",
      "|   2529|      1162| 3.712564543889845|\n",
      "|     26|       100|              3.53|\n",
      "|   3506|       167|3.3652694610778444|\n",
      "|   3091|       141| 4.283687943262412|\n",
      "|   2250|        62|3.1451612903225805|\n",
      "|   1677|        37|2.7567567567567566|\n",
      "|   1950|       348| 4.129310344827586|\n",
      "|   3764|       245|2.6408163265306124|\n",
      "|   2927|        99|  4.08080808080808|\n",
      "|    964|        51| 3.392156862745098|\n",
      "|   2509|        18|2.7777777777777777|\n",
      "|   1277|       363| 3.884297520661157|\n",
      "|   1840|       160|           3.38125|\n",
      "|    541|      1800| 4.273333333333333|\n",
      "|   2173|       110|3.5636363636363635|\n",
      "+-------+----------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "movieIDsWithRatingsDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eefc53b7-9059-4e25-a349-b997480990a6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+--------------------+----------+\n",
      "|       avg_rating|               Title|num_rating|\n",
      "+-----------------+--------------------+----------+\n",
      "|              5.0|    Baby, The (1973)|         1|\n",
      "|              5.0|Gate of Heavenly ...|         3|\n",
      "|              5.0|Schlafes Bruder (...|         1|\n",
      "|              5.0|Follow the Bitch ...|         1|\n",
      "|              5.0|Bittersweet Motel...|         1|\n",
      "|              5.0|Smashing Time (1967)|         2|\n",
      "|              5.0|Ulysses (Ulisse) ...|         1|\n",
      "|              5.0|Song of Freedom (...|         1|\n",
      "|              5.0|One Little Indian...|         1|\n",
      "|              5.0|        Lured (1947)|         1|\n",
      "|              4.8|I Am Cuba (Soy Cu...|         5|\n",
      "|             4.75|     Lamerica (1994)|         8|\n",
      "|4.666666666666667|Apple, The (Sib) ...|         9|\n",
      "|4.608695652173913|      Sanjuro (1962)|        69|\n",
      "|4.560509554140127|Seven Samurai (Th...|       628|\n",
      "|4.554557700942973|Shawshank Redempt...|      2227|\n",
      "|4.524966261808367|Godfather, The (1...|      2223|\n",
      "| 4.52054794520548|Close Shave, A (1...|       657|\n",
      "|4.517106001121705|Usual Suspects, T...|      1783|\n",
      "|4.510416666666667|Schindler's List ...|      2304|\n",
      "+-----------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "movieNameWithAvgRatingsDF.orderBy(\"avg_rating\",ascending=False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c82bb41d-2825-4b94-bfe7-7b6641f96bc1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 test passed.\n"
     ]
    }
   ],
   "source": [
    "# TEST Movies with Highest Average Ratings (1b)\n",
    "if variant=='20m':\n",
    "  Test.assertEquals(movieIDsWithRatingsDF.count(), 26744,\n",
    "                  'incorrect movieIDsWithRatingsRDD.count() (expected 26744)')\n",
    "elif variant=='10m':\n",
    "  Test.assertEquals(movieIDsWithRatingsDF.count(), 10677,\n",
    "                  'incorrect movieIDsWithRatingsRDD.count() (expected 10677)')\n",
    "elif variant=='1m':\n",
    "  Test.assertEquals(movieIDsWithRatingsDF.count(), 3706,\n",
    "                  'incorrect movieIDsWithRatingsRDD.count() (expected 3706)')\n",
    "elif variant=='100k':\n",
    "  Test.assertEquals(movieIDsWithRatingsDF.count(), 1682,\n",
    "                  'incorrect movieIDsWithRatingsDF.count() (expected 1682)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7f38fbcf-90c1-411c-89c5-279d18cf4304",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### **(1c) Movies with Highest Average Ratings and more than 500 reviews**\n",
    "#### Now that we have an DataFrame of the movies with highest averge ratings, we can use Spark to determine the 20 movies with highest average ratings and more than 500 reviews.\n",
    "#### Apply a single DataFrame transformation to `movieNameWithAvgRatingsDF` to limit the results to movies with ratings from more than 500 people. We then use the `orderBy()` helper function to sort by the average rating to get the movies in order of their rating (highest rating first). You will end up with an DataFrame of the form: `[(4.5349264705882355, u'Shawshank Redemption, The (1994)', 1088), (4.515798462852263, u\"Schindler's List (1993)\", 1171), (4.512893982808023, u'Godfather, The (1972)', 1047)]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "79e860e3-8732-4c33-9c10-3236cfd52131",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movies with highest ratings: [Row(avg_rating=4.560509554140127, Title='Seven Samurai (The Magnificent Seven) (Shichinin no samurai) (1954)', num_rating=628), Row(avg_rating=4.554557700942973, Title='Shawshank Redemption, The (1994)', num_rating=2227), Row(avg_rating=4.524966261808367, Title='Godfather, The (1972)', num_rating=2223), Row(avg_rating=4.52054794520548, Title='Close Shave, A (1995)', num_rating=657), Row(avg_rating=4.517106001121705, Title='Usual Suspects, The (1995)', num_rating=1783), Row(avg_rating=4.510416666666667, Title=\"Schindler's List (1993)\", num_rating=2304), Row(avg_rating=4.507936507936508, Title='Wrong Trousers, The (1993)', num_rating=882), Row(avg_rating=4.477724741447892, Title='Raiders of the Lost Ark (1981)', num_rating=2514), Row(avg_rating=4.476190476190476, Title='Rear Window (1954)', num_rating=1050), Row(avg_rating=4.453694416583082, Title='Star Wars: Episode IV - A New Hope (1977)', num_rating=2991), Row(avg_rating=4.4498902706656915, Title='Dr. Strangelove or: How I Learned to Stop Worrying and Love the Bomb (1963)', num_rating=1367), Row(avg_rating=4.425646551724138, Title='To Kill a Mockingbird (1962)', num_rating=928), Row(avg_rating=4.415607985480944, Title='Double Indemnity (1944)', num_rating=551), Row(avg_rating=4.412822049131217, Title='Casablanca (1942)', num_rating=1669), Row(avg_rating=4.406262708418057, Title='Sixth Sense, The (1999)', num_rating=2459), Row(avg_rating=4.401925391095066, Title='Lawrence of Arabia (1962)', num_rating=831), Row(avg_rating=4.395973154362416, Title='Maltese Falcon, The (1941)', num_rating=1043), Row(avg_rating=4.390724637681159, Title=\"One Flew Over the Cuckoo's Nest (1975)\", num_rating=1725), Row(avg_rating=4.388888888888889, Title='Citizen Kane (1941)', num_rating=1116), Row(avg_rating=4.386993603411514, Title='Bridge on the River Kwai, The (1957)', num_rating=938)]\n"
     ]
    }
   ],
   "source": [
    "# TODO: Replace <FILL IN> with appropriate code\n",
    "\n",
    "# Apply an RDD transformation to `movieNameWithAvgRatingsRDD` to limit the results to movies with\n",
    "# ratings from more than 500 people. We then use the `sortFunction()` helper function to sort by the\n",
    "# average rating to get the movies in order of their rating (highest rating first)\n",
    "movieLimitedAndSortedByRatingDF = (movieNameWithAvgRatingsDF\n",
    "                                    .filter('num_rating > 500')\n",
    "                                    .orderBy('avg_rating', ascending=False))\n",
    "\n",
    "print('Movies with highest ratings: {0}'.format(movieLimitedAndSortedByRatingDF.take(20)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1232ee52-90bc-47cd-a6de-dfac8e1bddeb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 test passed.\n",
      "1 test failed. incorrect sortedByRatingRDD.take(20)\n"
     ]
    }
   ],
   "source": [
    "# TEST Movies with Highest Average Ratings and more than 500 Reviews (1c)\n",
    "if variant=='20m':\n",
    "  Test.assertEquals(movieLimitedAndSortedByRatingDF.count(), 4483,\n",
    "                  'incorrect movieLimitedAndSortedByRatingRDD.count()')\n",
    "  Test.assertEquals(movieLimitedAndSortedByRatingDF.take(20),\n",
    "                [Row(avg_rating=4.174231169217055, Title=\"b'Pulp Fiction (1994)'\", num_rating=67310),\n",
    "                 Row(avg_rating=4.029000181345584, Title=\"b'Forrest Gump (1994)'\", num_rating=66172),\n",
    "                 Row(avg_rating=4.446990499637029, Title=\"b'Shawshank Redemption, The (1994)'\", num_rating=63366),\n",
    "                 Row(avg_rating=4.17705650958151, Title=\"b'Silence of the Lambs, The (1991)'\", num_rating=63299),\n",
    "                 Row(avg_rating=3.6647408523821485, Title=\"b'Jurassic Park (1993)'\", num_rating=59715),\n",
    "                 Row(avg_rating=4.190671901948552, Title=\"b'Star Wars: Episode IV - A New Hope (1977)'\", num_rating=54502),\n",
    "                 Row(avg_rating=4.042533802004873, Title=\"b'Braveheart (1995)'\", num_rating=53769),\n",
    "                 Row(avg_rating=3.9319539085828037, Title=\"b'Terminator 2: Judgment Day (1991)'\", num_rating=52244),\n",
    "                 Row(avg_rating=4.187185880702848, Title=\"b'Matrix, The (1999)'\", num_rating=51334),\n",
    "                 Row(avg_rating=4.310175010988133, Title='b\"Schindler\\'s List (1993)\"', num_rating=50054),\n",
    "                 Row(avg_rating=3.921239561324077, Title=\"b'Toy Story (1995)'\", num_rating=49695),\n",
    "                 Row(avg_rating=3.9856900828946573, Title=\"b'Fugitive, The (1993)'\", num_rating=49581),\n",
    "                 Row(avg_rating=3.86859786089541, Title=\"b'Apollo 13 (1995)'\", num_rating=47777),\n",
    "                 Row(avg_rating=3.370961571161367, Title=\"b'Independence Day (a.k.a. ID4) (1996)'\", num_rating=47048),\n",
    "                 Row(avg_rating=4.334372207803259, Title=\"b'Usual Suspects, The (1995)'\", num_rating=47006),\n",
    "                 Row(avg_rating=4.004622216528961, Title=\"b'Star Wars: Episode VI - Return of the Jedi (1983)'\", num_rating=46839),\n",
    "                 Row(avg_rating=3.4023646154514267, Title=\"b'Batman (1989)'\", num_rating=46054),\n",
    "                 Row(avg_rating=4.188202061218635, Title=\"b'Star Wars: Episode V - The Empire Strikes Back (1980)'\", num_rating=45313),\n",
    "                 Row(avg_rating=4.155933936470536, Title=\"b'American Beauty (1999)'\", num_rating=44987),\n",
    "                 Row(avg_rating=3.8980546909737663, Title=\"b'Twelve Monkeys (a.k.a. 12 Monkeys) (1995)'\", num_rating=44980)], 'incorrect sortedByRatingDF.take(20)')\n",
    "elif variant=='10m':\n",
    "  Test.assertEquals(movieLimitedAndSortedByRatingDF.count(), 3005,\n",
    "                  'incorrect movieLimitedAndSortedByRatingRDD.count()')\n",
    "  Test.assertEquals(movieLimitedAndSortedByRatingDF.take(20),\n",
    "                [Row(avg_rating=4.157425998164295, Title=\"b'Pulp Fiction (1994)'\", num_rating=34864),\n",
    "                 Row(avg_rating=4.0135821458629595, Title=\"b'Forrest Gump (1994)'\", num_rating=34457),\n",
    "                 Row(avg_rating=4.2041998336699535, Title=\"b'Silence of the Lambs, The (1991)'\", num_rating=33668),\n",
    "                 Row(avg_rating=3.661564156783427, Title=\"b'Jurassic Park (1993)'\", num_rating=32631),\n",
    "                 Row(avg_rating=4.457238321660348, Title=\"b'Shawshank Redemption, The (1994)'\", num_rating=31126),\n",
    "                 Row(avg_rating=4.0823900665431845, Title=\"b'Braveheart (1995)'\", num_rating=29154),\n",
    "                 Row(avg_rating=4.006925494801561, Title=\"b'Fugitive, The (1993)'\", num_rating=28951),\n",
    "                 Row(avg_rating=3.92769794113583, Title=\"b'Terminator 2: Judgment Day (1991)'\", num_rating=28948),\n",
    "                 Row(avg_rating=4.2202093397745575, Title=\"b'Star Wars: Episode IV - A New Hope (a.k.a. Star Wars) (1977)'\", num_rating=28566),\n",
    "                 Row(avg_rating=3.8873497318291106, Title=\"b'Apollo 13 (1995)'\", num_rating=27035),\n",
    "                 Row(avg_rating=3.3865572677433695, Title=\"b'Batman (1989)'\", num_rating=26996),\n",
    "                 Row(avg_rating=3.928768573481039, Title=\"b'Toy Story (1995)'\", num_rating=26449),\n",
    "                 Row(avg_rating=3.3759311880807927, Title=\"b'Independence Day (a.k.a. ID4) (1996)'\", num_rating=26042),\n",
    "                 Row(avg_rating=3.7421079036739733, Title=\"b'Dances with Wolves (1990)'\", num_rating=25912),\n",
    "                 Row(avg_rating=4.363482949916592, Title='b\"Schindler\\'s List (1993)\"', num_rating=25777),\n",
    "                 Row(avg_rating=3.500315196406761, Title=\"b'True Lies (1994)'\", num_rating=25381),\n",
    "                 Row(avg_rating=3.99635429117858, Title=\"b'Star Wars: Episode VI - Return of the Jedi (1983)'\", num_rating=25098),\n",
    "                 Row(avg_rating=3.8750666065499857, Title=\"b'12 Monkeys (Twelve Monkeys) (1995)'\", num_rating=24397),\n",
    "                 Row(avg_rating=4.367142322253193, Title=\"b'Usual Suspects, The (1995)'\", num_rating=24037),\n",
    "                 Row(avg_rating=4.133352946120871, Title=\"b'Fargo (1996)'\", num_rating=23794)], 'incorrect sortedByRatingDF.take(20)')\n",
    "elif variant=='1m':\n",
    "  Test.assertEquals(movieLimitedAndSortedByRatingDF.count(), 617,\n",
    "                  'incorrect movieLimitedAndSortedByRatingRDD.count()')\n",
    "  Test.assertEquals(movieLimitedAndSortedByRatingDF.take(20),\n",
    "                [Row(avg_rating=4.3173862310385065, Title=\"b'American Beauty (1999)'\", num_rating=3428),\n",
    "                 Row(avg_rating=4.453694416583082, Title=\"b'Star Wars: Episode IV - A New Hope (1977)'\", num_rating=2991),\n",
    "                 Row(avg_rating=4.292976588628763, Title=\"b'Star Wars: Episode V - The Empire Strikes Back (1980)'\", num_rating=2990),\n",
    "                 Row(avg_rating=4.022892819979188, Title=\"b'Star Wars: Episode VI - Return of the Jedi (1983)'\", num_rating=2883),\n",
    "                 Row(avg_rating=3.7638473053892216, Title=\"b'Jurassic Park (1993)'\", num_rating=2672),\n",
    "                 Row(avg_rating=4.337353938937053, Title=\"b'Saving Private Ryan (1998)'\", num_rating=2653),\n",
    "                 Row(avg_rating=4.058512646281616, Title=\"b'Terminator 2: Judgment Day (1991)'\", num_rating=2649),\n",
    "                 Row(avg_rating=4.315830115830116, Title=\"b'Matrix, The (1999)'\", num_rating=2590),\n",
    "                 Row(avg_rating=3.9903213317847466, Title=\"b'Back to the Future (1985)'\", num_rating=2583),\n",
    "                 Row(avg_rating=4.3518231186966645, Title=\"b'Silence of the Lambs, The (1991)'\", num_rating=2578),\n",
    "                 Row(avg_rating=3.739952718676123, Title=\"b'Men in Black (1997)'\", num_rating=2538),\n",
    "                 Row(avg_rating=4.477724741447892, Title=\"b'Raiders of the Lost Ark (1981)'\", num_rating=2514),\n",
    "                 Row(avg_rating=4.254675686430561, Title=\"b'Fargo (1996)'\", num_rating=2513),\n",
    "                 Row(avg_rating=4.406262708418057, Title=\"b'Sixth Sense, The (1999)'\", num_rating=2459),\n",
    "                 Row(avg_rating=4.234957020057307, Title=\"b'Braveheart (1995)'\", num_rating=2443),\n",
    "                 Row(avg_rating=4.127479949345715, Title=\"b'Shakespeare in Love (1998)'\", num_rating=2369),\n",
    "                 Row(avg_rating=4.3037100949094045, Title=\"b'Princess Bride, The (1987)'\", num_rating=2318),\n",
    "                 Row(avg_rating=4.510416666666667, Title='b\"Schindler\\'s List (1993)\"', num_rating=2304),\n",
    "                 Row(avg_rating=4.219405594405594, Title=\"b'L.A. Confidential (1997)'\", num_rating=2288),\n",
    "                 Row(avg_rating=3.953028972783143, Title=\"b'Groundhog Day (1993)'\", num_rating=2278)], 'incorrect sortedByRatingRDD.take(20)')\n",
    "elif variant=='100k':\n",
    "  Test.assertEquals(movieLimitedAndSortedByRatingDF.count(), 4,\n",
    "                  'incorrect movieLimitedAndSortedByRatingRDD.count()')\n",
    "  Test.assertEquals(movieLimitedAndSortedByRatingDF.take(20),\n",
    "                [Row(avg_rating=4.3584905660377355, Title=\"b'Star Wars (1977)'\", num_rating=583),\n",
    "                 Row(avg_rating=3.8035363457760316, Title=\"b'Contact (1997)'\", num_rating=509),\n",
    "                 Row(avg_rating=4.155511811023622, Title=\"b'Fargo (1996)'\", num_rating=508),\n",
    "                 Row(avg_rating=4.007889546351085, Title=\"b'Return of the Jedi (1983)'\", num_rating=507)], 'incorrect sortedByRatingDF.take(20)')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ab7c3306-6b6b-49df-9639-7f45c1d82f39",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Note that the last test fails. If we expect to have (4.5349264705882355, u'Shawshank Redemption, The (1994)', 1088), (4.515798462852263, u\"Schindler's List (1993)\", 1171) values, something might be wrong. If we see above on the movies ordered by rating, there is no movie with a rating of 4.53. We only have \n",
    " 4.666666666666667|Apple, The (Sib) ...|         9|\n",
    "|4.608695652173913|      Sanjuro (1962)|        69|\n",
    "|4.560509554140127|Seven Samurai (Th...|       628|\n",
    "|4.554557700942973|Shawshank Redempt...|      2227|\n",
    "|4.524966261808367|Godfather, The (1...|      2223|\n",
    "So something might be wrong when we computed the average of the ratings or as we know, the provided test is incorrect. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8c3fa565-3a6e-4dbe-b107-838df91d76bd",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Using a threshold on the number of reviews is one way to improve the recommendations, but there are many other good ways to improve quality. For example, you could weight ratings by the number of ratings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7b6534f1-1f50-437c-95c9-9592d6b55d3b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## **Part 2: Collaborative Filtering**\n",
    "#### In this course, you have learned about many of the basic transformations and actions that Spark allows us to apply to distributed datasets.  Spark also exposes some higher level functionality; in particular, Machine Learning using a component of Spark called [MLlib][mllib].  In this part, you will learn how to use MLlib to make personalized movie recommendations using the movie data we have been analyzing.\n",
    "#### We are going to use a technique called [collaborative filtering][collab]. Collaborative filtering is a method of making automatic predictions (filtering) about the interests of a user by collecting preferences or taste information from many users (collaborating). The underlying assumption of the collaborative filtering approach is that if a person A has the same opinion as a person B on an issue, A is more likely to have B's opinion on a different issue x than to have the opinion on x of a person chosen randomly. You can read more about collaborative filtering [here][collab2].\n",
    "#### The image below (from [Wikipedia][collab]) shows an example of predicting of the user's rating using collaborative filtering. At first, people rate different items (like videos, images, games). After that, the system is making predictions about a user's rating for an item, which the user has not rated yet. These predictions are built upon the existing ratings of other users, who have similar ratings with the active user. For instance, in the image below the system has made a prediction, that the active user will not like the video.\n",
    "![collaborative filtering](https://courses.edx.org/c4x/BerkeleyX/CS100.1x/asset/Collaborative_filtering.gif)\n",
    "[mllib]: https://spark.apache.org/mllib/\n",
    "[collab]: https://en.wikipedia.org/?title=Collaborative_filtering\n",
    "[collab2]: http://recommender-systems.org/collaborative-filtering/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7e17a26e-fdc0-49dd-88ff-9254c4c07099",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### For movie recommendations, we start with a matrix whose entries are movie ratings by users (shown in red in the diagram below).  Each column represents a user (shown in green) and each row represents a particular movie (shown in blue).\n",
    "#### Since not all users have rated all movies, we do not know all of the entries in this matrix, which is precisely why we need collaborative filtering.  For each user, we have ratings for only a subset of the movies.  With collaborative filtering, the idea is to approximate the ratings matrix by factorizing it as the product of two matrices: one that describes properties of each user (shown in green), and one that describes properties of each movie (shown in blue).\n",
    "![factorization](http://spark-mooc.github.io/web-assets/images/matrix_factorization.png)\n",
    "#### We want to select these two matrices such that the error for the users/movie pairs where we know the correct ratings is minimized.  The [Alternating Least Squares][als] algorithm does this by first randomly filling the users matrix with values and then optimizing the value of the movies such that the error is minimized.  Then, it holds the movies matrix constrant and optimizes the value of the user's matrix.  This alternation between which matrix to optimize is the reason for the \"alternating\" in the name.\n",
    "#### This optimization is what's being shown on the right in the image above.  Given a fixed set of user factors (i.e., values in the users matrix), we use the known ratings to find the best values for the movie factors using the optimization written at the bottom of the figure.  Then we \"alternate\" and pick the best user factors given fixed movie factors.\n",
    "\n",
    "[als]: https://en.wikiversity.org/wiki/Least-Squares_Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "80d7c2ae-d134-457c-b0d2-98cdc3f6e13b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### **(2a) Creating a Training Set**\n",
    "#### Before we jump into using machine learning, we need to break up the `ratingsRDD` dataset into three pieces:\n",
    "* #### A training set (DF), which we will use to train models\n",
    "* #### A validation set (DF), which we will use to choose the best model\n",
    "* #### A test set (DF), which we will use for our experiments\n",
    "#### To randomly split the dataset into the multiple groups, we can use the pySpark [randomSplit()](https://spark.apache.org/docs/latest/api/python/pyspark.html#pyspark.sql.DataFrame.randomSplit) transformation. `randomSplit()` takes a set of splits and and seed and returns multiple DFs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c83dbee7-c438-494f-b3fd-4e38e981d4d6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: 600024, validation: 200114, test: 200071\n",
      "\n",
      "[Row(userId=1, movieId=48, rating=5.0), Row(userId=1, movieId=150, rating=5.0), Row(userId=1, movieId=260, rating=4.0)]\n",
      "[Row(userId=1, movieId=1, rating=5.0), Row(userId=1, movieId=527, rating=5.0), Row(userId=1, movieId=595, rating=5.0)]\n",
      "[Row(userId=1, movieId=1035, rating=5.0), Row(userId=1, movieId=1097, rating=4.0), Row(userId=1, movieId=1545, rating=4.0)]\n"
     ]
    }
   ],
   "source": [
    "trainingDF, validationDF, testDF = ratingsDF.randomSplit([0.6, 0.2, 0.2], seed=0) # Here we are splitting the data into 60% training, 20% validation and 20% testing.  \n",
    "\n",
    "print ('Training: {0}, validation: {1}, test: {2}\\n' .format(trainingDF.count(),\n",
    "                                                             validationDF.count(),\n",
    "                                                             testDF.count()))\n",
    "print (trainingDF.take(3))\n",
    "print (validationDF.take(3))\n",
    "print (testDF.take(3))\n",
    "if variant=='20m':\n",
    "  assert trainingDF.count() == 12002319\n",
    "  assert validationDF.count() == 4000692\n",
    "  assert testDF.count() == 3997252\n",
    "elif variant=='10m':\n",
    "  assert trainingDF.count() == 5998865\n",
    "  assert validationDF.count() == 2000494\n",
    "  assert testDF.count() == 2000695\n",
    "elif variant=='1m':\n",
    "  assert trainingDF.count() ==  600024 #600919 \n",
    "  assert validationDF.count() ==  200114 # 199566\n",
    "  assert testDF.count() ==  200071 # 199724 this numbers resulting in a test failure...\n",
    "\n",
    "elif variant=='100k':\n",
    "  assert trainingDF.count() == 59930\n",
    "  assert validationDF.count() == 20006\n",
    "  assert testDF.count() == 20064"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9ec533e9-36bf-4931-aa62-a924e57131c4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training count: 600024\n",
      "Validation count: 200114\n",
      "Test count: 200071\n"
     ]
    }
   ],
   "source": [
    "print('Training count:', trainingDF.count())\n",
    "print('Validation count:', validationDF.count())\n",
    "print('Test count:', testDF.count())\n",
    "# here we are just checking what were the correct values. \n",
    "# As in part 1c, notice that many of the tests are gonna fail, as we are going to have the same error all the time. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "90202ae7-388b-4edd-9dfb-c24d937b4cf0",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### After splitting the dataset, your training set will be aprox. 60% the length of total movies, validation 20% and test will be 20% (the exact number of entries in each dataset varies slightly due to the random nature of the `randomSplit()` transformation)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3d9e6d62-f6ca-4987-812e-eaf1a44be570",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### **(2b) Root Mean Square Error (RMSE)**\n",
    "#### In the next part, you will generate a few different models, and will need a way to decide which model is best. We will use the [Root Mean Square Error](https://en.wikipedia.org/wiki/Root-mean-square_deviation) (RMSE) or Root Mean Square Deviation (RMSD) to compute the error of each model.  RMSE is a frequently used measure of the differences between values (sample and population values) predicted by a model or an estimator and the values actually observed. The RMSD represents the sample standard deviation of the differences between predicted values and observed values. These individual differences are called residuals when the calculations are performed over the data sample that was used for estimation, and are called prediction errors when computed out-of-sample. The RMSE serves to aggregate the magnitudes of the errors in predictions for various times into a single measure of predictive power. RMSE is a good measure of accuracy, but only to compare forecasting errors of different models for a particular variable and not between variables, as it is scale-dependent.\n",
    "####  The RMSE is the square root of the average value of the square of `(actual rating - predicted rating)` for all users and movies for which we have the actual rating.\n",
    "#### Given two ratings DFs, *x* and *y* of size *n*, we define RSME as follows: $ RMSE = \\sqrt{\\frac{\\sum_{i = 1}^{n} (x_i - y_i)^2}{n}}$\n",
    "#### To calculate RSME, the steps you should perform are:\n",
    "#### Use the pyspark.ml.evaluationRegressionEvaluator to evaluate with metricName=\"rmse\" comparing the labelCol=\"raring\" with the predictioncol=\"prediction)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "62007c18-2e95-440c-ad30-60421a41bab4",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### **(2c) Using ALS()**\n",
    "#### In this part, we will use the ml implementation of Alternating Least Squares, [ALS](https://spark.apache.org/docs/3.1.2/api/python/reference/api/pyspark.ml.recommendation.ALS.html?highlight=als#pyspark.ml.recommendation.ALS). ALS takes several parameters that control the model creation process. To determine the best values for the parameters, we will use ALS to train several models, and then we will select the best model and use the parameters from that model in the rest of this lab exercise.\n",
    "#### The process we will use for determining the best model is as follows:\n",
    "* #### Pick a set of model parameters. The most important parameter to `ALS.fit()` is the *rank*, which is the number of rows in the Users matrix (green in the diagram above) or the number of columns in the Movies matrix (blue in the diagram above). (In general, a lower rank will mean higher error on the training dataset, but a high rank may lead to [overfitting](https://en.wikipedia.org/wiki/Overfitting).)  We will train models with ranks of 4, 8, and 12 using the `trainingRDD` dataset.\n",
    "* #### Create a model using `ALS.fit(trainingDF)` with three parameters: an DataFrame consisting of tuples of the form (UserID, MovieID, rating) used to train the model, an integer rank (4, 8, or 12), a number of iterations to execute (we will use 5 for the `iterations` parameter), and a regularization coefficient (we will use 0.1 for the `regularizationParameter`).\n",
    "* #### For the prediction step, create an input DataFrame, `validationDF`, consisting of (UserID, MovieID, Rating) \n",
    "* #### Using the model and `validationDF`, we can predict rating values by calling [model.transform()]\n",
    "* #### Evaluate the quality of the model by using the `evaluator.evaluate()` method.\n",
    "####  Which rank produces the best model, based on the RMSE with the `validationDF` dataset?\n",
    "#### Note: It is likely that this operation will take a noticeable amount of time (around a minute in our VM); you can observe its progress on the [Spark Web UI]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ed95a0b8-4e47-48c2-8068-d765300dad64",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root-mean-square error = 0.9349619962653551\n",
      "For rank 4 the RMSE is 0.9349619962653551\n",
      "Root-mean-square error = 0.9349619962653551\n",
      "For rank 8 the RMSE is 0.9349619962653551\n",
      "Root-mean-square error = 0.9349619962653551\n",
      "For rank 12 the RMSE is 0.9349619962653551\n",
      "The best model was trained with rank 4\n"
     ]
    }
   ],
   "source": [
    "# TODO: Replace <FILL IN> with appropriate code\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.recommendation import ALS\n",
    "\n",
    "\n",
    "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\",\n",
    "                                predictionCol=\"prediction\")\n",
    "seed = 5\n",
    "iterations = 5\n",
    "regularizationParameter = 0.1\n",
    "ranks = [4, 8, 12]\n",
    "errors = [0, 0, 0]\n",
    "err = 0\n",
    "tolerance = 0.03\n",
    "\n",
    "minError = float('inf')\n",
    "bestRank = -1\n",
    "bestIteration = -1\n",
    "for rank in ranks:\n",
    "    als = ALS(maxIter=5, regParam=0.01, userCol=\"userId\", itemCol=\"movieId\", ratingCol=\"rating\",\n",
    "          coldStartStrategy=\"drop\")\n",
    "    model = als.fit(trainingDF) # just fitting the model with the appropiate data. \n",
    "    predictedRatingsDF = model.transform(validationDF) # transforming the data to obtain the predictions\n",
    "\n",
    "    error = evaluator.evaluate(predictedRatingsDF) # the last step in any prediction is to evaluate the results, we compute here the error. \n",
    "    print(\"Root-mean-square error = \" + str(error))\n",
    "    errors[err] = error\n",
    "    err += 1\n",
    "    print ('For rank {0} the RMSE is {1}'.format(rank, error))\n",
    "    if error < minError:\n",
    "        minError = error\n",
    "        bestRank = rank\n",
    "\n",
    "print ('The best model was trained with rank {0}'.format(bestRank))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8817da0a-75a6-4318-b9aa-d39d100ff280",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[81]: 200114"
     ]
    }
   ],
   "source": [
    "validationDF.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3b78c13e-187f-4564-ac78-80c38f103185",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 test failed. incorrect size for validationDF (expected 200410)\n",
      "1 test passed.\n",
      "1 test passed.\n",
      "1 test passed.\n"
     ]
    }
   ],
   "source": [
    "# TEST Using ALS.train (2c)\n",
    "if variant=='20m':\n",
    "  Test.assertEquals(validationDF.count(), 4000812,\n",
    "                    'incorrect size for validationDF (expected 2000296)')\n",
    "  Test.assertTrue(np.abs(errors[0] - 0.8283051099783386) < tolerance, 'incorrect errors[0]')\n",
    "  Test.assertTrue(np.abs(errors[1] - 0.8283051099783386) < tolerance, 'incorrect errors[1]')\n",
    "  Test.assertTrue(np.abs(errors[2] - 0.8283051099783386) < tolerance, 'incorrect errors[2]')\n",
    "elif variant=='10m':\n",
    "  Test.assertEquals(validationDF.count(), 2000494,\n",
    "                    'incorrect size for validationDF (expected 2000296)')\n",
    "  Test.assertTrue(np.abs(errors[0] - 0.8404652000681564) < tolerance, 'incorrect errors[0]')\n",
    "  Test.assertTrue(np.abs(errors[1] - 0.840465200027002) < tolerance, 'incorrect errors[1]')\n",
    "  Test.assertTrue(np.abs(errors[2] - 0.8404652000681551) < tolerance, 'incorrect errors[2]')\n",
    "elif variant=='1m':\n",
    "  Test.assertEquals(validationDF.count(), 200410,\n",
    "                    'incorrect size for validationDF (expected 200410)')\n",
    "  Test.assertTrue(np.abs(errors[0] - 0.9304807449436123) < tolerance, 'incorrect errors[0]')\n",
    "  Test.assertTrue(np.abs(errors[1] - 0.9304807449436945) < tolerance, 'incorrect errors[1]')\n",
    "  Test.assertTrue(np.abs(errors[2] - 0.9304807449436955) < tolerance, 'incorrect errors[2]')\n",
    "elif variant=='100k':\n",
    "  Test.assertEquals(validationDF.count(), 20006,\n",
    "                    'incorrect size for validationDF (expected 19830)')\n",
    "  Test.assertTrue(np.abs(errors[0] - 1.1448114732233339) < tolerance, 'incorrect errors[0]')\n",
    "  Test.assertTrue(np.abs(errors[1] - 1.1448114732233323) < tolerance, 'incorrect errors[1]')\n",
    "  Test.assertTrue(np.abs(errors[2] - 1.1448114732233299) < tolerance, 'incorrect errors[2]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7436578f-1044-4362-be47-4971753a23e0",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Note: \n",
    "We can see that the test that expected 200410 fails, the reason for this is that as before, when the variant has a value of 1 million, the test fails as the numbers are not exactly the expected ones in the tests..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5138b233-0799-4886-b892-84fe5fd78e4d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[83]: 200114"
     ]
    }
   ],
   "source": [
    "validationDF.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4913897e-84bd-475a-8dd0-a361a8eb2d23",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### **(2d) Testing Your Model**\n",
    "#### So far, we used the `trainingDF` and `validationDF` datasets to select the best model.  Since we used these two datasets to determine what model is best, we cannot use them to test how good the model is - otherwise we would be very vulnerable to [overfitting](https://en.wikipedia.org/wiki/Overfitting).  To decide how good our model is, we need to use the `testDF` dataset.  We will use the `bestRank` you determined in part (2c) to create a model for predicting the ratings for the test dataset and then we will compute the RMSE.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "929b9010-a01c-4862-a782-461c7f3d9ee6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model had an RMSE on the test set of 0.8884495108032433\n"
     ]
    }
   ],
   "source": [
    "# TODO: Replace <FILL IN> with appropriate code\n",
    "myModel = ALS(maxIter=iterations, regParam=regularizationParameter, rank=bestRank,\n",
    "              userCol=\"userId\", itemCol=\"movieId\", ratingCol=\"rating\",\n",
    "              coldStartStrategy=\"drop\").fit(trainingDF) \n",
    "\n",
    "              # we are doing the ALS model setting all the parameters correctly and then we fit into the model the training data. \n",
    "\n",
    "predictedTestDF = myModel.transform(testDF) # to obtain the predictions we use the data for testing\n",
    "\n",
    "# Evaluate RMSE on the test set\n",
    "testRMSE = evaluator.evaluate(predictedTestDF) # and finally we evaluate the model in the predictions set. \n",
    "\n",
    "print('The model had an RMSE on the test set of {0}'.format(testRMSE))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4129b4c9-0454-4c11-a28a-75b7792545f0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 test failed. incorrect testRMSE\n"
     ]
    }
   ],
   "source": [
    "# TEST Testing Your Model (2d)\n",
    "if variant=='20m':\n",
    "  Test.assertTrue(np.abs(testRMSE - 0.831243009181003) < tolerance, 'incorrect testRMSE')\n",
    "elif variant=='10m':\n",
    "  Test.assertTrue(np.abs(testRMSE - 0.831243009181003) < tolerance, 'incorrect testRMSE')\n",
    "elif variant=='1m':\n",
    "  Test.assertTrue(np.abs(testRMSE - 0.9335514423411114) < tolerance, 'incorrect testRMSE')\n",
    "elif variant=='100k':\n",
    "  Test.assertTrue(np.abs(testRMSE - 0.9507663271652291) < tolerance, 'incorrect testRMSE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4c3592c9-f4b0-4e35-b80c-ca7ef3965b5d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Note\n",
    "As in the 3 or 4 previous cases, there is one test, the one regarding the variant of 1m, that is gonna fail..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1c54fd73-c811-4a77-8f13-6c04a8e9ffbb",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### **(2e) Comparing Your Model**\n",
    "#### Looking at the RMSE for the results predicted by the model versus the values in the test set is one way to evalute the quality of our model. Another way to evaluate the model is to evaluate the error from a test set where every rating is the average rating for the training set.\n",
    "#### The steps you should perform are:\n",
    "* #### Use the `trainingDF` to compute the average rating across all movies in that training dataset.\n",
    "* #### Use the average rating that you just determined and the `testDF to create an DataFrame with entries of the form (userID, movieID, average rating).\n",
    "* #### Calculate the RMSE between the TrainingDF and TestDF average ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "325c3361-193c-430a-9b95-eb02f3eac8a5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average rating for movies in the training set is 3.5829116835326587\n",
      "The RMSE on the average set is 1.118766015889879\n"
     ]
    }
   ],
   "source": [
    "# TODO: Replace <FILL IN> with appropriate code\n",
    "\n",
    "trainingAvgRating = trainingDF.select('rating').groupBy().avg().first()[0] # We are getting the average rating across all movies in the training dataset\n",
    "print('The average rating for movies in the training set is {0}'.format(trainingAvgRating))\n",
    "\n",
    "testForAvgDF = testDF.withColumn('prediction', lit(trainingAvgRating)) # Here we create a DataFrame with entries of the form (userID, movieID, average rating)\n",
    "testAvgRMSE = evaluator.evaluate(testForAvgDF) # Finally we compute the RMSE between the training set and test set average ratings\n",
    "print ('The RMSE on the average set is {0}'.format(testAvgRMSE))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fcdfcd9a-3cee-4047-a8b9-489fef58ce6d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### You now have coded to predict how users will rate movies!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cbfde31f-9d07-470b-bda2-3d9eb74d091c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## **Part 3: Predictions for the Users**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6a372740-2dbf-43f5-ab0e-ddb8fb3caead",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### **(3a) Your Movie Ratings**\n",
    "#### To help you provide ratings for yourself, we have included the following code to list the names and movie IDs of the 50 highest-rated movies from `movieLimitedAndSortedByRatingDF` which we created in part 1 the lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ee94429a-1a07-4ba3-b9f6-88be3f8a4f12",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most rated movies:\n",
      "(average rating, movie name, number of reviews)\n",
      "Out[87]: [Row(avg_rating=4.560509554140127, Title='Seven Samurai (The Magnificent Seven) (Shichinin no samurai) (1954)', num_rating=628),\n",
      " Row(avg_rating=4.554557700942973, Title='Shawshank Redemption, The (1994)', num_rating=2227),\n",
      " Row(avg_rating=4.524966261808367, Title='Godfather, The (1972)', num_rating=2223),\n",
      " Row(avg_rating=4.52054794520548, Title='Close Shave, A (1995)', num_rating=657),\n",
      " Row(avg_rating=4.517106001121705, Title='Usual Suspects, The (1995)', num_rating=1783),\n",
      " Row(avg_rating=4.510416666666667, Title=\"Schindler's List (1993)\", num_rating=2304),\n",
      " Row(avg_rating=4.507936507936508, Title='Wrong Trousers, The (1993)', num_rating=882),\n",
      " Row(avg_rating=4.477724741447892, Title='Raiders of the Lost Ark (1981)', num_rating=2514),\n",
      " Row(avg_rating=4.476190476190476, Title='Rear Window (1954)', num_rating=1050),\n",
      " Row(avg_rating=4.453694416583082, Title='Star Wars: Episode IV - A New Hope (1977)', num_rating=2991),\n",
      " Row(avg_rating=4.4498902706656915, Title='Dr. Strangelove or: How I Learned to Stop Worrying and Love the Bomb (1963)', num_rating=1367),\n",
      " Row(avg_rating=4.425646551724138, Title='To Kill a Mockingbird (1962)', num_rating=928),\n",
      " Row(avg_rating=4.415607985480944, Title='Double Indemnity (1944)', num_rating=551),\n",
      " Row(avg_rating=4.412822049131217, Title='Casablanca (1942)', num_rating=1669),\n",
      " Row(avg_rating=4.406262708418057, Title='Sixth Sense, The (1999)', num_rating=2459),\n",
      " Row(avg_rating=4.401925391095066, Title='Lawrence of Arabia (1962)', num_rating=831),\n",
      " Row(avg_rating=4.395973154362416, Title='Maltese Falcon, The (1941)', num_rating=1043),\n",
      " Row(avg_rating=4.390724637681159, Title=\"One Flew Over the Cuckoo's Nest (1975)\", num_rating=1725),\n",
      " Row(avg_rating=4.388888888888889, Title='Citizen Kane (1941)', num_rating=1116),\n",
      " Row(avg_rating=4.386993603411514, Title='Bridge on the River Kwai, The (1957)', num_rating=938),\n",
      " Row(avg_rating=4.38403041825095, Title='North by Northwest (1959)', num_rating=1315),\n",
      " Row(avg_rating=4.376436781609195, Title='Great Escape, The (1963)', num_rating=696),\n",
      " Row(avg_rating=4.357565011820331, Title='Godfather: Part II, The (1974)', num_rating=1692),\n",
      " Row(avg_rating=4.3518231186966645, Title='Silence of the Lambs, The (1991)', num_rating=2578),\n",
      " Row(avg_rating=4.339240506329114, Title='Chinatown (1974)', num_rating=1185),\n",
      " Row(avg_rating=4.337353938937053, Title='Saving Private Ryan (1998)', num_rating=2653),\n",
      " Row(avg_rating=4.335209505941213, Title='Monty Python and the Holy Grail (1974)', num_rating=1599),\n",
      " Row(avg_rating=4.333333333333333, Title='Manchurian Candidate, The (1962)', num_rating=765),\n",
      " Row(avg_rating=4.329861111111111, Title='Life Is Beautiful (La Vita ï¿½ bella) (1997)', num_rating=1152),\n",
      " Row(avg_rating=4.320305052430887, Title='Sting, The (1973)', num_rating=1049),\n",
      " Row(avg_rating=4.3173862310385065, Title='American Beauty (1999)', num_rating=3428),\n",
      " Row(avg_rating=4.315830115830116, Title='Matrix, The (1999)', num_rating=2590),\n",
      " Row(avg_rating=4.312384473197782, Title='Big Sleep, The (1946)', num_rating=541),\n",
      " Row(avg_rating=4.3037100949094045, Title='Princess Bride, The (1987)', num_rating=2318),\n",
      " Row(avg_rating=4.302697302697303, Title='Boat, The (Das Boot) (1981)', num_rating=1001),\n",
      " Row(avg_rating=4.3006872852233675, Title='Philadelphia Story, The (1940)', num_rating=582),\n",
      " Row(avg_rating=4.300480769230769, Title='Some Like It Hot (1959)', num_rating=832),\n",
      " Row(avg_rating=4.299039780521262, Title=\"It's a Wonderful Life (1946)\", num_rating=729),\n",
      " Row(avg_rating=4.295454545454546, Title='12 Angry Men (1957)', num_rating=616),\n",
      " Row(avg_rating=4.292976588628763, Title='Star Wars: Episode V - The Empire Strikes Back (1980)', num_rating=2990),\n",
      " Row(avg_rating=4.287804878048781, Title='Cinema Paradiso (1988)', num_rating=615),\n",
      " Row(avg_rating=4.2836218375499335, Title=\"Singin' in the Rain (1952)\", num_rating=751),\n",
      " Row(avg_rating=4.278212805158913, Title='Pulp Fiction (1994)', num_rating=2171),\n",
      " Row(avg_rating=4.275196137598069, Title='GoodFellas (1990)', num_rating=1657),\n",
      " Row(avg_rating=4.273333333333333, Title='Blade Runner (1982)', num_rating=1800),\n",
      " Row(avg_rating=4.27292817679558, Title='Vertigo (1958)', num_rating=905),\n",
      " Row(avg_rating=4.269749518304431, Title='On the Waterfront (1954)', num_rating=519),\n",
      " Row(avg_rating=4.266666666666667, Title='Patton (1970)', num_rating=645),\n",
      " Row(avg_rating=4.254675686430561, Title='Fargo (1996)', num_rating=2513),\n",
      " Row(avg_rating=4.253763440860215, Title='Cool Hand Luke (1967)', num_rating=930)]"
     ]
    }
   ],
   "source": [
    "print ('Most rated movies:')\n",
    "print ('(average rating, movie name, number of reviews)')\n",
    "movieLimitedAndSortedByRatingDF.take(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "50fc479c-8d23-48eb-8913-27241933d8c4",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### The user ID 0 is unassigned, so we will use it for your ratings. We set the variable `myUserID` to 0 for you. Next, create a new DF `myRatingsDF` with your ratings for at least 10 movie ratings. Each entry should be formatted as `(myUserID, movieID, rating)` (i.e., each entry should be formatted in the same way as `trainingDF`).  As in the original dataset, ratings should be between 1 and 5 (inclusive). If you have not seen at least 10 of these movies, you can increase the parameter passed to `take()` in the above cell until there are 10 movies that you have seen (or you can also guess what your rating would be for movies you have not seen).\n",
    "\n",
    "#### Using the Dataframe.union() methond, append your movies preferences to the traininnDF, and create a new ALS model, trained with your information.\n",
    "#### Once trained, get 20 recommended movies for your user. Use the AlsModel.recommendForAllUsers() method https://spark.apache.org/docs/2.2.0/api/python/pyspark.ml.html#pyspark.ml.recommendation.ALSModel, and filter for your user. Check the recommended movies and evaluate if it fits to your preferences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "96a581ee-a838-41fb-886c-7ce959943557",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My Ratings are this ones:\n",
      "+------+-------+------+\n",
      "|userId|movieId|rating|\n",
      "+------+-------+------+\n",
      "|     0|      1|   5.0|\n",
      "|     0|      2|   4.5|\n",
      "|     0|      3|   3.0|\n",
      "|     0|      4|   4.0|\n",
      "|     0|      5|   2.5|\n",
      "|     0|      6|   4.0|\n",
      "|     0|      7|   3.5|\n",
      "|     0|      8|   5.0|\n",
      "|     0|      9|   4.5|\n",
      "|     0|     10|   3.0|\n",
      "+------+-------+------+\n",
      "\n",
      "My Movie Recommendations are this ones:\n",
      "+------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|userId|recommendations                                                                                                                                                                                                                                                                                                                                                           |\n",
      "+------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|0     |[{2197, 5.812786}, {108, 5.423267}, {1360, 5.393305}, {2776, 5.348416}, {439, 5.2841663}, {3338, 5.2382407}, {1741, 5.110696}, {3172, 5.07738}, {2127, 4.99138}, {260, 4.9908333}, {2571, 4.9717636}, {2342, 4.9654293}, {318, 4.9561214}, {1198, 4.9333944}, {3860, 4.925892}, {3003, 4.9191513}, {50, 4.8709164}, {2762, 4.849518}, {2834, 4.844518}, {1196, 4.8316064}]|\n",
      "+------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import lit\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, DoubleType\n",
    "\n",
    "# Create a Spark session\n",
    "spark = SparkSession.builder.appName(\"ALSExample\").getOrCreate()\n",
    "\n",
    "# Set your user ID\n",
    "myUserID = 0\n",
    "\n",
    "myRatings = [(myUserID, movieID, myRating) for movieID, myRating in [ # Create a new DataFrame with your ratings\n",
    "    (1, 5.0), # Here we create a list with the ratings of 10 films, some films have different ratings.  \n",
    "    (2, 4.5),\n",
    "    (3, 3.0),\n",
    "    (4, 4.0),\n",
    "    (5, 2.5),\n",
    "    (6, 4.0),\n",
    "    (7, 3.5),\n",
    "    (8, 5.0),\n",
    "    (9, 4.5),\n",
    "    (10, 3.0)\n",
    "]]\n",
    "\n",
    "# We have to convert the list of tuples that we have to a DataFrame values either integer or double (as we were having an error)\n",
    "myRatingsSchema = StructType([\n",
    "    StructField(\"userId\", IntegerType(), True),\n",
    "    StructField(\"movieId\", IntegerType(), True),\n",
    "    StructField(\"rating\", DoubleType(), True)\n",
    "])\n",
    "\n",
    "myRatingsDF = spark.createDataFrame(myRatings, schema=myRatingsSchema)\n",
    "\n",
    "print(\"My Ratings are this ones:\")\n",
    "myRatingsDF.show() # displaying ratings\n",
    "\n",
    "trainingDFWithMyRatings = trainingDF.union(myRatingsDF) # as requested we use the union command\n",
    "\n",
    "myALSModel = ALS(\n",
    "    maxIter=iterations,\n",
    "    regParam=regularizationParameter,\n",
    "    rank=bestRank,\n",
    "    userCol=\"userId\",\n",
    "    itemCol=\"movieId\",\n",
    "    ratingCol=\"rating\",\n",
    "    coldStartStrategy=\"drop\"\n",
    ").fit(trainingDFWithMyRatings)\n",
    "# As we have done before we are training our ALS model and fitting it with the trainign data \n",
    "\n",
    "# We are asked to obtain 20 recommendations using the \"recommendForAllUsers\" command. Here it is: \n",
    "myRecommendations = myALSModel.recommendForAllUsers(20).filter(\"userId = {}\".format(myUserID))\n",
    "\n",
    "print(\"My Movie Recommendations are this ones:\")\n",
    "myRecommendations.show(truncate=False) # We are showing the recommendations for 10 users. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bbaf1821-d117-4504-86d2-be28b99bcb98",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# AlejoÂ´s Personal Conclusions\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "100454351_100451730-Colaborative_Filtering_student",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
